{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9b0984-5096-4c21-9a69-0457d09e2263",
   "metadata": {},
   "source": [
    "# Implementation of the ResNet as sole network \n",
    "Self implemented based on the tutorials about ResNets\n",
    "\n",
    "The here trained ResNet has 110 layers --> ResNet-54\n",
    "\n",
    "Goal: comparison of single RNet with Blockdrop in testing AND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8863c5c-0ef6-4272-8f56-931677ddf5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as torchdata\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6317c6-3410-4995-b6ba-d1dd60ea449a",
   "metadata": {},
   "source": [
    "# Model of ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1db5ef6-ab21-4628-bfbb-8f6517d3a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self reimplemted based on ResNet tutorial: https://pytorch-tutorial.readthedocs.io/en/latest/tutorial/chapter03_intermediate/3_2_2_cnn_resnet_cifar10/\n",
    "# 3x3 convolution: \n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block consists of following steps:\n",
    "# 1. 3x3 conv 2. Batch Normalization 3. ReLU 4. 3x3 Convolution 5. Batch Normalization \n",
    "# at the end, addition of the identity function (= skipping function = input of layer)\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_in, num_out, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(num_in, num_out, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(num_out)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(num_out, num_out)\n",
    "        self.bn2 = nn.BatchNorm2d(num_out)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x # to get input of layer for identity function\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "        x += residual\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "# ResNet consists of following steps:\n",
    "# 1. normal convolutional layer (input, conv, batch_norm, relu) \n",
    "# 2. x Residual blocks (parted in three units for downsampling) \n",
    "# 3. avg. pooling \n",
    "# 4. fully connected layer: gives back the final output\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8e6b24-8fe2-4dd4-94ac-d315abe1aaff",
   "metadata": {},
   "source": [
    "# Training of ResNet\n",
    "Procedure based on PyTorch tutorial by Thorben\n",
    "\n",
    "Steps:\n",
    "1. Move input data to device \n",
    "2. Run the model on the input data\n",
    "3. Calculate the loss\n",
    "4. Perform backpropagation\n",
    "5. Update the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be73dc8-7f95-4886-a4c3-c8858be3fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet(model, optimizer, data_loader, loss_module, num_epochs=1):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch \", epoch)\n",
    "        for batch_idx, (data_inputs, data_labels) in tqdm.tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ## Step 1: Move input data to device\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels = data_labels.to(device, non_blocking=True)\n",
    "\n",
    "            ## Step 2: Run the model on the input data\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1)\n",
    "\n",
    "            ## Step 3: Calculate the loss\n",
    "            loss = loss_module(preds, data_labels)\n",
    "\n",
    "            ## Step 4: Perform backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            ## Step 5: Update the parameters\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e250d-8554-4a6a-8b46-96ce97097990",
   "metadata": {},
   "source": [
    "# Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "616b3d9d-485a-46d7-b51c-40608d962345",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute accuracy\n",
    "def get_accuracy(preds, target, batch_size):\n",
    "    corrects = (torch.max(preds, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6746d12d-bcf4-4a7c-9544-55791b4de64a",
   "metadata": {},
   "source": [
    "# Testing\n",
    "For each batch:\n",
    "    1. execute model on batch \n",
    "    2. evalulate accuravy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4665ec55-5a3d-41b1-8741-5c6ad20d34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_resnet(model, data_loader):\n",
    "    acc = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch_id, (data_inputs, data_labels) in tqdm.tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            acc += get_accuracy(preds, data_labels, len(data_labels))\n",
    "    accuracy = acc/batch_id\n",
    "    print(f\"Accuracy of the model: {acc/batch_id:4.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b801f-a1ab-4087-866e-9986154a6b30",
   "metadata": {},
   "source": [
    "# Combining all components\n",
    "\n",
    "1. Create model\n",
    "2. Get and transform data\n",
    "3. Train model\n",
    "4. Test model\n",
    "5. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005345c-8af1-45d2-b1c1-2a8e4c1a2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='data/'\n",
    "## Step 1: Create model\n",
    "layer_config = [18, 18, 18] #110 layer resnet\n",
    "model_name = \"110_layer\"\n",
    "batch_size = 256\n",
    "#layer_config = [5, 5, 5] #for 32 layer Resnet\n",
    "model = ResNet(ResidualBlock, layer_config)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "## Step 2: Data\n",
    "#image preprocessing; used for training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "trainset = datasets.CIFAR10(root=root, train=True, download=False, transform= transform)#transform_train)\n",
    "testset = datasets.CIFAR10(root=root, train=False, download=False, transform=transforms.ToTensor())#transform_test)\n",
    "\n",
    "\n",
    "num_workers = 4 if torch.device(\"cuda\") else 1\n",
    "\n",
    "trainloader = torchdata.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers) #50000 images\n",
    "testloader = torchdata.DataLoader(testset, batch_size=1, shuffle=False, num_workers=num_workers) #10000 images\n",
    "\n",
    "## Step 3: Training\n",
    "# parameters:\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #lr parameter as proposed in BlockDrop implementation\n",
    "loss = nn.CrossEntropyLoss()\n",
    "num_epochs = 100\n",
    "\n",
    "start_training_single = timer()\n",
    "train_resnet(model, optimizer, trainloader, loss, num_epochs)\n",
    "end_training_single = timer()\n",
    "training_time_single = end_training_single -start_training_single\n",
    "\n",
    "## Step 4: Testing\n",
    "model.eval()\n",
    "start_testing_single = timer()\n",
    "test_resnet(model, testloader)\n",
    "end_testing_single = timer()\n",
    "## Step 5: Save model\n",
    "state_dict = model.state_dict()\n",
    "torch.save(state_dict, 'cv/trained_rnet/'+ model_name + '/Epoch_%d.t7'%(num_epochs))\n",
    "testing_time_single = end_testing_single - start_testing_single\n",
    "\n",
    "\n",
    "\"Training in s: %.2f, Testing per image in ms: %.2f\"%(training_time_single, 1000*testing_time_single/len(testset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
